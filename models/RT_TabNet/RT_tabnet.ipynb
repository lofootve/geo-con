{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-tabnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 용어 정리\n",
    "- event\n",
    "- class\n",
    "- instance\n",
    "- observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/louan/Documents/projects/Aiffel/Hackathon/geodata-con/geo-con/models/RT_TabNet'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from datasets import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler # 표준화 패키지 라이브러리\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from warnings import filterwarnings\n",
    "import gc\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_integration as di\n",
    "filterwarnings('ignore')\n",
    "device = torch.device('cpu')\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../3W/dataset/0/*.csv\n",
      "../../../3W/dataset/1/*.csv\n",
      "../../../3W/dataset/2/*.csv\n",
      "../../../3W/dataset/3/*.csv\n",
      "../../../3W/dataset/4/*.csv\n",
      "../../../3W/dataset/5/*.csv\n",
      "../../../3W/dataset/6/*.csv\n",
      "../../../3W/dataset/7/*.csv\n",
      "../../../3W/dataset/8/*.csv\n"
     ]
    }
   ],
   "source": [
    "# 전체 file list 만들기\n",
    "path = '../../../3W/dataset/' # write the path of your '3W/dataset/'\n",
    "for event in range(9):\n",
    "    file_lst = []\n",
    "    full_path = path + f'{event}/*.csv'\n",
    "    file_lst.extend(sorted(glob(full_path)))\n",
    "    globals()['df_event_{}'.format(event)] = di.dt_integration(file_lst)\n",
    "    globals()['df_event_{}'.format(event)].drop(columns = ['timestamp', 'event_type', 'P-JUS-CKGL', 'T-JUS-CKGL', 'QGL', 'instance_type'], inplace = True)\n",
    "    globals()['df_event_{}'.format(event)].reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interplolate_without_class(df, method='linear'):\n",
    "    '''\n",
    "    input (df) : 라벨 단위 observation_df\n",
    "    output (df) : 라벨 단위 observation_df\n",
    "    기본 보간 방법은 선형 보간\n",
    "    '''\n",
    "    columns = df.columns\n",
    "    columns = columns.drop('class')\n",
    "    class_observations = df['class']\n",
    "\n",
    "    df = df[columns].interpolate(method = method)\n",
    "    df['class'] = class_observations\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WELL-00001_20170201020207_0', 'WELL-00001_20170201070114_0',\n",
      "       'WELL-00001_20170201120124_0', 'WELL-00001_20170201170311_0',\n",
      "       'WELL-00001_20170201220228_0', 'WELL-00001_20170202030343_0',\n",
      "       'WELL-00001_20170202080239_0', 'WELL-00001_20170218010146_0',\n",
      "       'WELL-00001_20170218060218_0', 'WELL-00001_20170218110218_0',\n",
      "       ...\n",
      "       'WELL-00006_20170827030218_0', 'WELL-00006_20170827080114_0',\n",
      "       'WELL-00006_20170827130321_0', 'WELL-00006_20170827180146_0',\n",
      "       'WELL-00006_20170827230218_0', 'WELL-00006_20170828040343_0',\n",
      "       'WELL-00006_20170828090311_0', 'WELL-00006_20170828140031_0',\n",
      "       'WELL-00007_20170801180000_0', 'WELL-00007_20170801200000_0'],\n",
      "      dtype='object', length=511)\n",
      "0 라벨의 최종 관측 개수: 8431490\n",
      "Index(['DRAWN_00001_1', 'DRAWN_00002_1', 'DRAWN_00003_1', 'DRAWN_00004_1',\n",
      "       'DRAWN_00005_1', 'DRAWN_00006_1', 'DRAWN_00007_1', 'DRAWN_00008_1',\n",
      "       'DRAWN_00009_1', 'DRAWN_00010_1',\n",
      "       ...\n",
      "       'SIMULATED_00109_1', 'SIMULATED_00110_1', 'SIMULATED_00111_1',\n",
      "       'SIMULATED_00112_1', 'SIMULATED_00113_1', 'SIMULATED_00114_1',\n",
      "       'WELL-00001_20140124093303_1', 'WELL-00006_20170731180930_1',\n",
      "       'WELL-00006_20170731220432_1', 'WELL-00006_20180617200257_1'],\n",
      "      dtype='object', length=128)\n",
      "1 라벨의 최종 관측 개수: 9158432\n",
      "Index(['SIMULATED_00001_2', 'SIMULATED_00002_2', 'SIMULATED_00003_2',\n",
      "       'SIMULATED_00004_2', 'SIMULATED_00005_2', 'SIMULATED_00006_2',\n",
      "       'SIMULATED_00007_2', 'SIMULATED_00008_2', 'SIMULATED_00009_2',\n",
      "       'SIMULATED_00010_2', 'SIMULATED_00011_2', 'SIMULATED_00012_2',\n",
      "       'SIMULATED_00013_2', 'SIMULATED_00014_2', 'SIMULATED_00015_2',\n",
      "       'SIMULATED_00016_2', 'WELL-00002_20131104014101_2',\n",
      "       'WELL-00009_20170313160804_2', 'WELL-00010_20171218190131_2'],\n",
      "      dtype='object')\n",
      "2 라벨의 최종 관측 개수: 486452\n",
      "Index(['SIMULATED_00001_3', 'SIMULATED_00002_3', 'SIMULATED_00003_3',\n",
      "       'SIMULATED_00004_3', 'SIMULATED_00005_3', 'SIMULATED_00006_3',\n",
      "       'SIMULATED_00007_3', 'SIMULATED_00008_3', 'SIMULATED_00009_3',\n",
      "       'SIMULATED_00010_3',\n",
      "       ...\n",
      "       'WELL-00014_20170925110124_3', 'WELL-00014_20170925160218_3',\n",
      "       'WELL-00014_20170925210042_3', 'WELL-00014_20170926020340_3',\n",
      "       'WELL-00014_20170926070042_3', 'WELL-00014_20170926120103_3',\n",
      "       'WELL-00014_20170926170228_3', 'WELL-00014_20171028080000_3',\n",
      "       'WELL-00014_20171028130000_3', 'WELL-00014_20171028180038_3'],\n",
      "      dtype='object', length=106)\n",
      "3 라벨의 최종 관측 개수: 4834079\n",
      "Index(['WELL-00001_20170316120203_4', 'WELL-00001_20170316140000_4',\n",
      "       'WELL-00001_20170316160005_4', 'WELL-00001_20170316180000_4',\n",
      "       'WELL-00001_20170316200000_4', 'WELL-00001_20170316220000_4',\n",
      "       'WELL-00001_20170317000000_4', 'WELL-00001_20170317020000_4',\n",
      "       'WELL-00001_20170317040000_4', 'WELL-00001_20170317060000_4',\n",
      "       ...\n",
      "       'WELL-00014_20170917020012_4', 'WELL-00014_20170917040228_4',\n",
      "       'WELL-00014_20170917060111_4', 'WELL-00014_20170917080112_4',\n",
      "       'WELL-00014_20170917100055_4', 'WELL-00014_20170917120016_4',\n",
      "       'WELL-00014_20170923160033_4', 'WELL-00014_20170923180059_4',\n",
      "       'WELL-00014_20170923200120_4', 'WELL-00014_20170924170050_4'],\n",
      "      dtype='object', length=344)\n",
      "4 라벨의 최종 관측 개수: 2462076\n",
      "Index(['SIMULATED_00001_5', 'SIMULATED_00002_5', 'SIMULATED_00003_5',\n",
      "       'SIMULATED_00004_5', 'SIMULATED_00005_5', 'SIMULATED_00006_5',\n",
      "       'SIMULATED_00007_5', 'SIMULATED_00008_5', 'SIMULATED_00009_5',\n",
      "       'SIMULATED_00010_5',\n",
      "       ...\n",
      "       'SIMULATED_00433_5', 'SIMULATED_00434_5', 'SIMULATED_00435_5',\n",
      "       'SIMULATED_00436_5', 'SIMULATED_00437_5', 'SIMULATED_00438_5',\n",
      "       'SIMULATED_00439_5', 'WELL-00015_20170620040530_5',\n",
      "       'WELL-00017_20140314135248_5', 'WELL-00017_20140319031616_5'],\n",
      "      dtype='object', length=442)\n",
      "5 라벨의 최종 관측 개수: 13161262\n",
      "Index(['WELL-00002_20140212170333_6', 'WELL-00002_20140301151700_6',\n",
      "       'WELL-00002_20140325170304_6', 'WELL-00004_20171031181509_6',\n",
      "       'WELL-00004_20171031190706_6', 'WELL-00004_20171031194452_6'],\n",
      "      dtype='object')\n",
      "6 라벨의 최종 관측 개수: 56578\n",
      "Index(['DRAWN_00001_7', 'DRAWN_00002_7', 'DRAWN_00003_7', 'DRAWN_00004_7',\n",
      "       'DRAWN_00005_7', 'DRAWN_00006_7', 'DRAWN_00007_7', 'DRAWN_00008_7',\n",
      "       'DRAWN_00009_7', 'DRAWN_00010_7', 'WELL-00001_20170226140146_7',\n",
      "       'WELL-00006_20180617181315_7', 'WELL-00006_20180620155728_7',\n",
      "       'WELL-00018_20180611021218_7', 'WELL-00018_20190403023307_7'],\n",
      "      dtype='object')\n",
      "7 라벨의 최종 관측 개수: 2885548\n"
     ]
    }
   ],
   "source": [
    "threshold = 10\n",
    "events = 9 # 0부터 8번까지의 이벤트를 따로따로 저장함\n",
    "\n",
    "before_interpolation_description = []\n",
    "after_interpolation_description = []\n",
    "observation_nums_lst = []\n",
    "\n",
    "for event in tqdm(range(event)):\n",
    "    #1. 인스턴스 별 칼럼의 결측 비율 조사\n",
    "    df = globals()['df_event_{}'.format(event)]\n",
    "    missing_proportion_df = di.missing_data_proportion(df)\n",
    "\n",
    "    #2. Threshold 이상의 observation만 남기고 나머지 observation 제거\n",
    "    index = missing_proportion_df[(missing_proportion_df > threshold).sum(axis=1) == 0].index\n",
    "    # print(index) to be deleted\n",
    "    df = df[df['id_label'].isin(index)]\n",
    "    print(f\"{event} 라벨의 최종 관측 개수: {len(df)}\")\n",
    "\n",
    "    #3. 라벨 제외한 df 보간\n",
    "    globals()['df_event_{}'.format(event)] = interplolate_without_class(df, method = 'linear')\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier 제거 및 변화율 \n",
    "- 참고: https://stackoverflow.com/questions/35827863/remove-outliers-in-pandas-dataframe-using-percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add delta and remove outlier\n",
    "def add_delta(data_frame):\n",
    "    for column in ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP']:\n",
    "        column_pctchg = column+'_pctchg'\n",
    "        data_frame[column_pctchg] = data_frame.groupby(['id_label'])[column].pct_change()\n",
    "        data_frame[column_pctchg][data_frame[column_pctchg].isna()] = 0\n",
    "    return data_frame\n",
    "\n",
    "def remove_outlier(df):\n",
    "    target_cols = ['P-PDG', 'P-TPT', 'T-TPT','P-MON-CKP', 'T-JUS-CKP',]\n",
    "    df = df[df['id_label'].str.startswith('WELL')]\n",
    "    df = add_delta(df)\n",
    "    Q1 = df[target_cols].quantile(0.25)\n",
    "    Q3 = df[target_cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[~((df[target_cols] < (Q1 - 1.5 * IQR)) | (df[target_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_num: 0\n",
      "event_num: 1\n",
      "event_num: 2\n",
      "event_num: 3\n",
      "event_num: 4\n",
      "event_num: 5\n",
      "event_num: 6\n",
      "event_num: 7\n",
      "event_num: 8\n"
     ]
    }
   ],
   "source": [
    "# outlier 제거\n",
    "for i in range(9):\n",
    "    print(f'event_type: {i} removing outlier')\n",
    "    globals()['df_event_{}_out'.format(i)] = remove_outlier(globals()['df_event_{}'.format(i)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the list of each data type(WELL, SIMULATED, DRAWN)\n",
    "instance_dict = {'WELL': [], 'SIMULATED': [], 'DRAWN': []}\n",
    "for i in range(9):\n",
    "  instance_lst = list(globals()['df_event_{}'.format(i)]['id_label'].unique())\n",
    "  for instance in instance_lst:\n",
    "    if instance.startswith('WELL'):\n",
    "      instance_dict['WELL'].extend([instance])\n",
    "    elif instance.startswith('SIMULATED'):\n",
    "      instance_dict['SIMULATED'].extend([instance])\n",
    "    elif instance.startswith('DRAWN'):\n",
    "      instance_dict['DRAWN'].extend([instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'0': 511, '4': 344, '3': 32, '6': 6, '7': 5, '1': 4, '2': 3, '5': 3})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of events in 'WELL' data\n",
    "class_lst = []\n",
    "for i in instance_dict['WELL']:\n",
    "  class_lst.append(i.split('_')[-1])\n",
    "Counter(class_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test instances\n",
    "def split_train_test_instance(instance_dict, dTypes = ['WELL', 'SIMULATED', 'DRAWN'],train_ratio = 0.6, test_ratio = 0.2):\n",
    "    total_len = 0\n",
    "    simul_drawn_lst = []\n",
    "    for dType in dTypes:\n",
    "        total_len += len(instance_dict[dType])\n",
    "        simul_drawn_lst += instance_dict[dType]\n",
    "    well_len = len(instance_dict['WELL'])\n",
    "\n",
    "    num_of_test = int(total_len*test_ratio)\n",
    "    num_of_val = int(total_len*(1-train_ratio-test_ratio))\n",
    "    num_of_train = total_len - num_of_test - num_of_val\n",
    "\n",
    "    # extract test_lst first(Only WELL data)\n",
    "    test_lst = random.sample(instance_dict['WELL'], num_of_test)\n",
    "    \n",
    "    # then make whole lst --> shuffle lst --> split train validation set\n",
    "    rest_well_lst = [i for i in instance_dict['WELL'] if i not in test_lst]\n",
    "    total_lst = rest_well_lst + simul_drawn_lst\n",
    "    random.shuffle(total_lst)\n",
    "\n",
    "    train_lst = total_lst[:num_of_train]\n",
    "    val_lst = total_lst[num_of_train:]\n",
    "\n",
    "    return train_lst, val_lst, test_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158\n",
      "1155\n",
      "247\n",
      "total number of lst: 1652\n",
      "total number of lst after removing duplicated: 1652\n",
      "train:\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8']\n",
      "val:\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8']\n",
      "test:\n",
      "['0', '3', '4', '5', '7']\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.7\n",
    "test_ratio = 0.15\n",
    "val_ratio = 1 - train_ratio - test_ratio\n",
    "dTypes = ['WELL', 'SIMULATED', 'DRAWN']\n",
    "train_lst, val_lst, test_lst = split_train_test_instance(instance_dict, dTypes = dTypes, train_ratio = train_ratio, test_ratio = test_ratio)\n",
    "\n",
    "# print(len(train_lst), len(val_lst), len(test_lst), sep = '\\n')\n",
    "# print('total number of lst:', len(instance_dict['WELL'])+len(instance_dict['DRAWN'])+len(instance_dict['SIMULATED']))\n",
    "# print('total number of lst after removing duplicated:', len(set(train_lst + val_lst + test_lst)))\n",
    "# print('train:', sorted(set([i.split('_')[-1] for i in train_lst])), 'val:', sorted(set([i.split('_')[-1] for i in val_lst])), 'test:', sorted(set([i.split('_')[-1] for i in test_lst])), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고: https://rfriend.tistory.com/590\n",
    "def make_empty_df(pca_n_components):\n",
    "    pca_lst = ['pca_1', 'pca_2','pca_3', 'pca_4', 'pca_5']\n",
    "    columns = ['P-PDG', 'P-PDG_std','P-PDG_pctchg_mean', 'P-PDG_pctchg_std',\n",
    "               'P-TPT', 'P-TPT_std', 'P-TPT_pctchg_mean', 'P-TPT_pctchg_std',\n",
    "               'T-TPT', 'T-TPT_std', 'T-TPT_pctchg_mean', 'T-TPT_pctchg_std',\n",
    "               'P-MON-CKP', 'P-MON-CKP_std', 'P-MON-CKP_pctchg_mean', 'P-MON-CKP_pctchg_std',\n",
    "               'T-JUS-CKP', 'T-JUS-CKP_std', 'T-JUS-CKP_pctchg_mean', 'T-JUS-CKP_pctchg_std',\n",
    "               'class',]\n",
    "    columns.extend(pca_lst[:pca_n_components])\n",
    "    data_frame = pd.DataFrame(columns=columns)\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def apply_window(data_frame, window_size = 5000, overlap_ratio = 0.2, pca_n_components = 2):\n",
    "    if pca_n_components:\n",
    "        pca = PCA(n_components=pca_n_components)\n",
    "    \n",
    "    new_df = make_empty_df(pca_n_components)\n",
    "    for n in tqdm(range(int(len(data_frame)/(window_size*(1-overlap_ratio))))):\n",
    "        try:\n",
    "            if int(window_size*(n+1) - window_size*overlap_ratio*n) <= len(data_frame):\n",
    "                # print(window_size*n*(1-overlap_ratio),window_size*(n+1) - window_size*overlap_ratio*n)\n",
    "                sliced_df = data_frame[int(window_size*n*(1-overlap_ratio)):int(window_size*(n+1) - window_size*overlap_ratio*n)]\n",
    "                pca_data = pca.fit_transform(sliced_df.drop( ['id_label','class'], axis=1))\n",
    "                if any(sliced_df['class'] != 0):\n",
    "                    class_label =  int(sliced_df['class'].value_counts().index[sliced_df['class'].value_counts().index < 10][0]) # 기본 모드\n",
    "                    \n",
    "                    # class_label = 1\n",
    "                else:\n",
    "                    # continue\n",
    "                    class_label = 0\n",
    "                new_df = pd.concat([new_df,pd.DataFrame({'P-PDG':[sliced_df['P-PDG'].mean()],\n",
    "                                                        'P-PDG_std':[sliced_df['P-PDG'].std()],\n",
    "                                                        'P-PDG_pctchg_mean':[sliced_df['P-PDG_pctchg'].mean()],\n",
    "                                                        'P-PDG_pctchg_std':[sliced_df['P-PDG_pctchg'].std()],\n",
    "                                                        'P-TPT':[sliced_df['P-TPT'].mean()],\n",
    "                                                        'P-TPT_std':[sliced_df['P-TPT'].std()],\n",
    "                                                        'P-TPT_pctchg_mean':[sliced_df['P-TPT_pctchg'].mean()],\n",
    "                                                        'P-TPT_pctchg_std':[sliced_df['P-TPT_pctchg'].std()],\n",
    "                                                        'T-TPT':[sliced_df['T-TPT'].mean()],\n",
    "                                                        'T-TPT_std':[sliced_df['T-TPT'].std()],\n",
    "                                                        'T-TPT_pctchg_mean':[sliced_df['T-TPT_pctchg'].mean()],\n",
    "                                                        'T-TPT_pctchg_std':[sliced_df['T-TPT_pctchg'].std()],\n",
    "                                                        'P-MON-CKP':[sliced_df['P-MON-CKP'].mean()],\n",
    "                                                        'P-MON-CKP_std':[sliced_df['P-MON-CKP'].std()],\n",
    "                                                        'P-MON-CKP_pctchg_mean':[sliced_df['P-MON-CKP_pctchg'].mean()],\n",
    "                                                        'P-MON-CKP_pctchg_std':[sliced_df['P-MON-CKP_pctchg'].std()],\n",
    "                                                        'T-JUS-CKP':[sliced_df['T-JUS-CKP'].mean()],\n",
    "                                                        'T-JUS-CKP_std':[sliced_df['T-JUS-CKP'].std()],\n",
    "                                                        'T-JUS-CKP_pctchg_mean':[sliced_df['T-JUS-CKP_pctchg'].mean()],\n",
    "                                                        'T-JUS-CKP_pctchg_std':[sliced_df['T-JUS-CKP_pctchg'].std()],\n",
    "                                                        'class': class_label,\n",
    "                                                        'pca_1':[pca_data[:,0].mean()],\n",
    "                                                        'pca_2':[pca_data[:,1].mean()],\n",
    "                                                        #'pca_3':[pca_data.iloc[:,2].mean()],\n",
    "                                                        })])\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    return new_df\n",
    "\n",
    "def build_dataset(data_frame, train_lst, val_lst, test_lst, window_size = 5000, overlap_ratio = 0.2, pca_n_components = 2):\n",
    "  gc.collect()\n",
    "  train_data_frame = data_frame[data_frame['id_label'].isin(train_lst)]\n",
    "  val_data_frame = data_frame[data_frame['id_label'].isin(val_lst)]\n",
    "  test_data_frame = data_frame[data_frame['id_label'].isin(test_lst)]\n",
    "\n",
    "#   train_data_frame = remove_outlier(train_data_frame)\n",
    "\n",
    "  train_df = apply_window(train_data_frame, window_size = window_size, overlap_ratio = overlap_ratio)\n",
    "  val_df = apply_window(val_data_frame, window_size = window_size, overlap_ratio = overlap_ratio)\n",
    "  test_df = apply_window(test_data_frame, window_size = window_size, overlap_ratio = overlap_ratio)\n",
    "  return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61459/61459 [08:15<00:00, 123.96it/s]\n",
      "100%|██████████| 63485/63485 [07:57<00:00, 132.99it/s]\n",
      "100%|██████████| 21348/21348 [02:30<00:00, 141.51it/s]\n",
      "100%|██████████| 3244/3244 [00:19<00:00, 169.05it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 275/275 [00:01<00:00, 167.86it/s]\n",
      "100%|██████████| 365/365 [00:02<00:00, 139.42it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 5906/5906 [00:42<00:00, 137.88it/s]\n",
      "100%|██████████| 4777/4777 [00:34<00:00, 136.64it/s]\n",
      "100%|██████████| 3818/3818 [00:26<00:00, 142.56it/s]\n",
      "100%|██████████| 22162/22162 [02:46<00:00, 133.04it/s]\n",
      "100%|██████████| 22094/22094 [02:46<00:00, 132.48it/s]\n",
      "100%|██████████| 9338/9338 [01:06<00:00, 140.99it/s]\n",
      "100%|██████████| 3921/3921 [00:17<00:00, 221.85it/s]\n",
      "100%|██████████| 1504/1504 [00:07<00:00, 191.51it/s]\n",
      "100%|██████████| 2417/2417 [00:09<00:00, 242.49it/s]\n",
      "100%|██████████| 385/385 [00:02<00:00, 152.59it/s]\n",
      "100%|██████████| 791/791 [00:05<00:00, 147.43it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 4390/4390 [00:21<00:00, 201.22it/s]\n",
      "100%|██████████| 4512/4512 [00:20<00:00, 215.52it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying window\n",
    "window_size = 1200\n",
    "window_size_short = window_size\n",
    "window_size_long =  window_size\n",
    "pca_n_components = 2\n",
    "overlap_ratio = 0.95\n",
    "\n",
    "df_event_0_window_train, df_event_0_window_val, df_event_0_window_test = build_dataset(df_event_0_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_1_window_train, df_event_1_window_val, df_event_1_window_test = build_dataset(df_event_1_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_2_window_train, df_event_2_window_val, df_event_2_window_test = build_dataset(df_event_2_out, train_lst, val_lst, test_lst, window_size = window_size_short, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_3_window_train, df_event_3_window_val, df_event_3_window_test = build_dataset(df_event_3_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_4_window_train, df_event_4_window_val, df_event_4_window_test = build_dataset(df_event_4_out, train_lst, val_lst, test_lst, window_size = window_size_short, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_5_window_train, df_event_5_window_val, df_event_5_window_test = build_dataset(df_event_5_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_6_window_train, df_event_6_window_val, df_event_6_window_test = build_dataset(df_event_6_out, train_lst, val_lst, test_lst, window_size = window_size_short, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_7_window_train, df_event_7_window_val, df_event_7_window_test = build_dataset(df_event_7_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_8_window_train, df_event_8_window_val, df_event_8_window_test = build_dataset(df_event_8_out, train_lst, val_lst, test_lst, window_size = window_size_short, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling train dataset\n",
    "merged_df_train =  pd.concat([df_event_0_window_train.sample(int(len(df_event_0_window_train)*0.2)),\n",
    "                              df_event_1_window_train,\n",
    "                              df_event_2_window_train,\n",
    "                              df_event_3_window_train.sample(int(len(df_event_3_window_train)*0.5)),\n",
    "                              df_event_4_window_train.sample(int(len(df_event_4_window_train)*0.2)),\n",
    "                              df_event_5_window_train,\n",
    "                              df_event_6_window_train,\n",
    "                              df_event_7_window_train,\n",
    "                              df_event_8_window_train])\n",
    "\n",
    "merged_df_val =  pd.concat([df_event_0_window_val,\n",
    "                            df_event_1_window_val,\n",
    "                            df_event_2_window_val,\n",
    "                            df_event_3_window_val,\n",
    "                            df_event_4_window_val,\n",
    "                            df_event_5_window_val,\n",
    "                            df_event_6_window_val,\n",
    "                            df_event_7_window_val,\n",
    "                            df_event_8_window_val])\n",
    "\n",
    "merged_df_test =  pd.concat([df_event_0_window_test,\n",
    "                             df_event_1_window_test,\n",
    "                             df_event_2_window_test,\n",
    "                             df_event_3_window_test,\n",
    "                             df_event_4_window_test,\n",
    "                             df_event_5_window_test,\n",
    "                             df_event_6_window_test,\n",
    "                             df_event_7_window_test,\n",
    "                             df_event_8_window_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17633\n",
      "4     4428\n",
      "3     2943\n",
      "6       96\n",
      "5       70\n",
      "7       64\n",
      "2       58\n",
      "Name: class, dtype: int64\n",
      "0    66164\n",
      "4    22055\n",
      "3     4758\n",
      "6      218\n",
      "2       64\n",
      "7       59\n",
      "5       30\n",
      "Name: class, dtype: int64\n",
      "0    21410\n",
      "4     9310\n",
      "3     3799\n",
      "5       30\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(merged_df_train['class'].value_counts())\n",
    "# print(merged_df_val['class'].value_counts())\n",
    "# print(merged_df_test['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-PDG_pctchg_mean = -inf, 혹은 inf인 row 제외: train(14개), val(10개), test(13)\n",
    "merged_df_train = merged_df_train[~merged_df_train['P-PDG_pctchg_std'].isna()]\n",
    "merged_df_val = merged_df_val[~merged_df_val['P-PDG_pctchg_std'].isna()]\n",
    "merged_df_test = merged_df_test[~merged_df_test['P-PDG_pctchg_std'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-PDG_std</th>\n",
       "      <th>P-PDG_pctchg_mean</th>\n",
       "      <th>P-PDG_pctchg_std</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>P-TPT_std</th>\n",
       "      <th>P-TPT_pctchg_mean</th>\n",
       "      <th>P-TPT_pctchg_std</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>T-TPT_std</th>\n",
       "      <th>...</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>P-MON-CKP_std</th>\n",
       "      <th>P-MON-CKP_pctchg_mean</th>\n",
       "      <th>P-MON-CKP_pctchg_std</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>T-JUS-CKP_std</th>\n",
       "      <th>T-JUS-CKP_pctchg_mean</th>\n",
       "      <th>T-JUS-CKP_pctchg_std</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.513980e+06</td>\n",
       "      <td>44250.598242</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>118.649417</td>\n",
       "      <td>0.074481</td>\n",
       "      <td>...</td>\n",
       "      <td>1.705502e+06</td>\n",
       "      <td>197762.811138</td>\n",
       "      <td>-1.069346e-05</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>73.865260</td>\n",
       "      <td>0.534615</td>\n",
       "      <td>1.553172e-05</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>3.104409e-11</td>\n",
       "      <td>5.277495e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.251894e+06</td>\n",
       "      <td>11768.755682</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>117.081695</td>\n",
       "      <td>0.032046</td>\n",
       "      <td>...</td>\n",
       "      <td>1.738947e+06</td>\n",
       "      <td>235685.005274</td>\n",
       "      <td>2.397799e-04</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>74.262885</td>\n",
       "      <td>0.409763</td>\n",
       "      <td>-9.940235e-06</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>9.313226e-12</td>\n",
       "      <td>4.470348e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.210455e+06</td>\n",
       "      <td>16480.355557</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>117.338862</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>...</td>\n",
       "      <td>1.510929e+06</td>\n",
       "      <td>231516.942956</td>\n",
       "      <td>2.233274e-04</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>74.310319</td>\n",
       "      <td>0.333256</td>\n",
       "      <td>5.990106e-07</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>-7.761021e-12</td>\n",
       "      <td>-4.610047e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.139513e+06</td>\n",
       "      <td>13153.825435</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>116.946400</td>\n",
       "      <td>0.021037</td>\n",
       "      <td>...</td>\n",
       "      <td>1.712754e+06</td>\n",
       "      <td>242015.276350</td>\n",
       "      <td>-2.613143e-04</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>73.995591</td>\n",
       "      <td>0.506100</td>\n",
       "      <td>-3.963848e-07</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>7.605801e-11</td>\n",
       "      <td>1.358179e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.520466e+06</td>\n",
       "      <td>20623.757181</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>117.630498</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500295e+06</td>\n",
       "      <td>239900.723194</td>\n",
       "      <td>9.003129e-05</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>76.527279</td>\n",
       "      <td>0.470989</td>\n",
       "      <td>-2.489537e-06</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>1.055499e-10</td>\n",
       "      <td>-8.436230e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>3.096140e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.078746e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.142814</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>...</td>\n",
       "      <td>1.107130e+07</td>\n",
       "      <td>4943.190623</td>\n",
       "      <td>-2.452558e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>69.341553</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>1.089206e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.094850e+26</td>\n",
       "      <td>5.820766e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>3.096140e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.078746e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.141607</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>...</td>\n",
       "      <td>1.107156e+07</td>\n",
       "      <td>4883.483012</td>\n",
       "      <td>9.712145e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>69.345515</td>\n",
       "      <td>0.059899</td>\n",
       "      <td>4.368168e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.094850e+26</td>\n",
       "      <td>-1.940255e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>3.096140e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.078746e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.140617</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>...</td>\n",
       "      <td>1.107207e+07</td>\n",
       "      <td>4658.242472</td>\n",
       "      <td>5.985480e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>69.346796</td>\n",
       "      <td>0.059158</td>\n",
       "      <td>1.142284e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.094850e+26</td>\n",
       "      <td>1.940255e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>3.096140e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.078746e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.140404</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>...</td>\n",
       "      <td>1.107242e+07</td>\n",
       "      <td>4581.638458</td>\n",
       "      <td>4.441322e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>69.355407</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>2.365953e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>3.094850e+26</td>\n",
       "      <td>-1.940255e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.180116e+42</td>\n",
       "      <td>3.096140e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.078746e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.141566</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>...</td>\n",
       "      <td>1.107294e+07</td>\n",
       "      <td>4085.714567</td>\n",
       "      <td>1.059609e-06</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>69.365419</td>\n",
       "      <td>0.058269</td>\n",
       "      <td>2.433330e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>3.094850e+26</td>\n",
       "      <td>1.940255e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25292 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           P-PDG     P-PDG_std  P-PDG_pctchg_mean  P-PDG_pctchg_std  \\\n",
       "0   0.000000e+00  0.000000e+00                0.0               0.0   \n",
       "0   0.000000e+00  0.000000e+00                0.0               0.0   \n",
       "0   0.000000e+00  0.000000e+00                0.0               0.0   \n",
       "0   0.000000e+00  0.000000e+00                0.0               0.0   \n",
       "0   0.000000e+00  0.000000e+00                0.0               0.0   \n",
       "..           ...           ...                ...               ...   \n",
       "0  -1.180116e+42  3.096140e+26                0.0               0.0   \n",
       "0  -1.180116e+42  3.096140e+26                0.0               0.0   \n",
       "0  -1.180116e+42  3.096140e+26                0.0               0.0   \n",
       "0  -1.180116e+42  3.096140e+26                0.0               0.0   \n",
       "0  -1.180116e+42  3.096140e+26                0.0               0.0   \n",
       "\n",
       "           P-TPT     P-TPT_std  P-TPT_pctchg_mean  P-TPT_pctchg_std  \\\n",
       "0   8.513980e+06  44250.598242           0.000010          0.000022   \n",
       "0   8.251894e+06  11768.755682          -0.000004          0.000025   \n",
       "0   8.210455e+06  16480.355557           0.000005          0.000002   \n",
       "0   8.139513e+06  13153.825435          -0.000002          0.000014   \n",
       "0   8.520466e+06  20623.757181           0.000005          0.000022   \n",
       "..           ...           ...                ...               ...   \n",
       "0   2.078746e+07      0.000000           0.000000          0.000000   \n",
       "0   2.078746e+07      0.000000           0.000000          0.000000   \n",
       "0   2.078746e+07      0.000000           0.000000          0.000000   \n",
       "0   2.078746e+07      0.000000           0.000000          0.000000   \n",
       "0   2.078746e+07      0.000000           0.000000          0.000000   \n",
       "\n",
       "         T-TPT  T-TPT_std  ...     P-MON-CKP  P-MON-CKP_std  \\\n",
       "0   118.649417   0.074481  ...  1.705502e+06  197762.811138   \n",
       "0   117.081695   0.032046  ...  1.738947e+06  235685.005274   \n",
       "0   117.338862   0.030220  ...  1.510929e+06  231516.942956   \n",
       "0   116.946400   0.021037  ...  1.712754e+06  242015.276350   \n",
       "0   117.630498   0.020783  ...  1.500295e+06  239900.723194   \n",
       "..         ...        ...  ...           ...            ...   \n",
       "0   118.142814   0.010842  ...  1.107130e+07    4943.190623   \n",
       "0   118.141607   0.010670  ...  1.107156e+07    4883.483012   \n",
       "0   118.140617   0.011122  ...  1.107207e+07    4658.242472   \n",
       "0   118.140404   0.011407  ...  1.107242e+07    4581.638458   \n",
       "0   118.141566   0.011207  ...  1.107294e+07    4085.714567   \n",
       "\n",
       "    P-MON-CKP_pctchg_mean  P-MON-CKP_pctchg_std  T-JUS-CKP  T-JUS-CKP_std  \\\n",
       "0           -1.069346e-05              0.008611  73.865260       0.534615   \n",
       "0            2.397799e-04              0.009897  74.262885       0.409763   \n",
       "0            2.233274e-04              0.010244  74.310319       0.333256   \n",
       "0           -2.613143e-04              0.009960  73.995591       0.506100   \n",
       "0            9.003129e-05              0.010342  76.527279       0.470989   \n",
       "..                    ...                   ...        ...            ...   \n",
       "0           -2.452558e-07              0.000013  69.341553       0.059850   \n",
       "0            9.712145e-07              0.000013  69.345515       0.059899   \n",
       "0            5.985480e-07              0.000013  69.346796       0.059158   \n",
       "0            4.441322e-07              0.000013  69.355407       0.059855   \n",
       "0            1.059609e-06              0.000012  69.365419       0.058269   \n",
       "\n",
       "    T-JUS-CKP_pctchg_mean  T-JUS-CKP_pctchg_std         pca_1         pca_2  \n",
       "0            1.553172e-05              0.000364  3.104409e-11  5.277495e-11  \n",
       "0           -9.940235e-06              0.000261  9.313226e-12  4.470348e-10  \n",
       "0            5.990106e-07              0.000210 -7.761021e-12 -4.610047e-10  \n",
       "0           -3.963848e-07              0.000346  7.605801e-11  1.358179e-10  \n",
       "0           -2.489537e-06              0.000294  1.055499e-10 -8.436230e-10  \n",
       "..                    ...                   ...           ...           ...  \n",
       "0            1.089206e-06              0.000003  3.094850e+26  5.820766e-13  \n",
       "0            4.368168e-07              0.000006  3.094850e+26 -1.940255e-13  \n",
       "0            1.142284e-06              0.000011  3.094850e+26  1.940255e-13  \n",
       "0            2.365953e-06              0.000013  3.094850e+26 -1.940255e-13  \n",
       "0            2.433330e-06              0.000013  3.094850e+26  1.940255e-13  \n",
       "\n",
       "[25292 rows x 22 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['P-PDG', 'P-PDG_std','P-PDG_pctchg_mean', 'P-PDG_pctchg_std',\n",
    "            'P-TPT', 'P-TPT_std', 'P-TPT_pctchg_mean', 'P-TPT_pctchg_std',\n",
    "            'T-TPT', 'T-TPT_std', 'T-TPT_pctchg_mean', 'T-TPT_pctchg_std',\n",
    "            'P-MON-CKP', 'P-MON-CKP_std', 'P-MON-CKP_pctchg_mean', 'P-MON-CKP_pctchg_std',\n",
    "            'T-JUS-CKP', 'T-JUS-CKP_std', 'T-JUS-CKP_pctchg_mean', 'T-JUS-CKP_pctchg_std',\n",
    "            'pca_1', 'pca_2']\n",
    "X_train_pre, y_train = merged_df_train.loc[:,features], merged_df_train['class']\n",
    "X_train_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "# Pandas automatically applies colomn-wise function in the code above.\n",
    "# merged_new_df = (merged_df - merged_df.mean())/merged_df.std()\n",
    "features = ['P-PDG', 'P-PDG_std','P-PDG_pctchg_mean', 'P-PDG_pctchg_std',\n",
    "            'P-TPT', 'P-TPT_std', 'P-TPT_pctchg_mean', 'P-TPT_pctchg_std',\n",
    "            'T-TPT', 'T-TPT_std', 'T-TPT_pctchg_mean', 'T-TPT_pctchg_std',\n",
    "            'P-MON-CKP', 'P-MON-CKP_std', 'P-MON-CKP_pctchg_mean', 'P-MON-CKP_pctchg_std',\n",
    "            'T-JUS-CKP', 'T-JUS-CKP_std', 'T-JUS-CKP_pctchg_mean', 'T-JUS-CKP_pctchg_std',\n",
    "            'pca_1', 'pca_2']\n",
    "\n",
    "X_train_pre, y_train = merged_df_train.loc[:,features], merged_df_train['class']\n",
    "X_val_pre, y_val = merged_df_val.loc[:,features], merged_df_val['class']\n",
    "X_test_pre, y_test = merged_df_test.loc[:,features], merged_df_test['class']\n",
    "\n",
    "# 각 칼럼의 std는 정규화에서 제외\n",
    "columns = ['P-PDG', 'P-PDG_pctchg_mean','P-TPT','P-TPT_pctchg_mean', 'T-TPT','T-TPT_pctchg_mean', 'P-MON-CKP','P-MON-CKP_pctchg_mean', 'T-JUS-CKP','T-JUS-CKP_pctchg_mean',\n",
    "           'P-PDG_std', 'P-TPT_std', 'T-TPT_std', 'P-MON-CKP_std', 'T-JUS-CKP_std',\n",
    "           'pca_1', 'pca_2']\n",
    "\n",
    "X_train_pre.loc[:,columns] = (X_train_pre.loc[:,columns] - X_train_pre.loc[:,columns].mean())/X_train_pre.loc[:,columns].std()\n",
    "X_val_pre.loc[:,columns] = (X_val_pre.loc[:,columns] - X_val_pre.loc[:,columns].mean())/X_val_pre.loc[:,columns].std()\n",
    "X_test_pre.loc[:,columns] = (X_test_pre.loc[:,columns] - X_test_pre.loc[:,columns].mean())/X_test_pre.loc[:,columns].std()\n",
    "\n",
    "X_train = X_train_pre\n",
    "X_val = X_val_pre\n",
    "X_test = X_test_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "X_train = X_train[features].values\n",
    "y_train = y_train.values.astype(int)\n",
    "\n",
    "X_val = X_val[features].values\n",
    "y_val = y_val.values.astype(int)\n",
    "\n",
    "X_test = X_test[features].values\n",
    "y_test = y_test.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "optimizer_fn = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=0.0001)\n",
    "batch_size = 64\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW, 0.7,  0.15, 0.15, long = 1200 short = 1200, 0.95, lr = {'lr': 0.0001}, batch_size = 64, no_weigth_loss, patience = 10, val_acc = ?, test_acc = ?, no Norm, no Simul\n",
      "0 is in event, 17633\n",
      "2 is in event, 58\n",
      "3 is in event, 2943\n",
      "4 is in event, 4428\n",
      "5 is in event, 70\n",
      "6 is in event, 96\n",
      "7 is in event, 64\n",
      "tensor([0.3028, 0.9977, 0.8836, 0.8249, 0.9972, 0.9962, 0.9975])\n",
      "epoch 0  | loss: 2.5072  | val_0_accuracy: 0.33197 |  0:00:08s\n",
      "epoch 1  | loss: 2.20898 | val_0_accuracy: 0.438   |  0:00:16s\n",
      "epoch 2  | loss: 1.96213 | val_0_accuracy: 0.40697 |  0:00:26s\n",
      "epoch 3  | loss: 1.74451 | val_0_accuracy: 0.40908 |  0:00:35s\n",
      "epoch 4  | loss: 1.53917 | val_0_accuracy: 0.3577  |  0:00:44s\n",
      "epoch 5  | loss: 1.39632 | val_0_accuracy: 0.3698  |  0:00:52s\n",
      "epoch 6  | loss: 1.27662 | val_0_accuracy: 0.37437 |  0:01:00s\n",
      "epoch 7  | loss: 1.15218 | val_0_accuracy: 0.39563 |  0:01:09s\n",
      "epoch 8  | loss: 1.08151 | val_0_accuracy: 0.42398 |  0:01:17s\n",
      "epoch 9  | loss: 1.01916 | val_0_accuracy: 0.45291 |  0:01:25s\n",
      "epoch 10 | loss: 0.96055 | val_0_accuracy: 0.54527 |  0:01:34s\n",
      "epoch 11 | loss: 0.91129 | val_0_accuracy: 0.67347 |  0:01:42s\n",
      "epoch 12 | loss: 0.86607 | val_0_accuracy: 0.71384 |  0:01:50s\n",
      "epoch 13 | loss: 0.8068  | val_0_accuracy: 0.80333 |  0:01:59s\n",
      "epoch 14 | loss: 0.76009 | val_0_accuracy: 0.82752 |  0:02:07s\n",
      "epoch 15 | loss: 0.71338 | val_0_accuracy: 0.86045 |  0:02:15s\n",
      "epoch 16 | loss: 0.65764 | val_0_accuracy: 0.8715  |  0:02:24s\n",
      "epoch 17 | loss: 0.61969 | val_0_accuracy: 0.88536 |  0:02:32s\n",
      "epoch 18 | loss: 0.59019 | val_0_accuracy: 0.89468 |  0:02:40s\n",
      "epoch 19 | loss: 0.5506  | val_0_accuracy: 0.90895 |  0:02:48s\n",
      "epoch 20 | loss: 0.51384 | val_0_accuracy: 0.90548 |  0:02:57s\n",
      "epoch 21 | loss: 0.49195 | val_0_accuracy: 0.93134 |  0:03:05s\n",
      "epoch 22 | loss: 0.46984 | val_0_accuracy: 0.94207 |  0:03:13s\n",
      "epoch 23 | loss: 0.44958 | val_0_accuracy: 0.93756 |  0:03:22s\n",
      "epoch 24 | loss: 0.42061 | val_0_accuracy: 0.94098 |  0:03:30s\n",
      "epoch 25 | loss: 0.412   | val_0_accuracy: 0.94636 |  0:03:38s\n",
      "epoch 26 | loss: 0.40449 | val_0_accuracy: 0.94637 |  0:03:46s\n",
      "epoch 27 | loss: 0.38421 | val_0_accuracy: 0.94788 |  0:03:55s\n",
      "epoch 28 | loss: 0.3757  | val_0_accuracy: 0.94919 |  0:04:03s\n",
      "epoch 29 | loss: 0.35853 | val_0_accuracy: 0.94974 |  0:04:11s\n",
      "epoch 30 | loss: 0.35732 | val_0_accuracy: 0.95046 |  0:04:19s\n",
      "epoch 31 | loss: 0.34741 | val_0_accuracy: 0.94571 |  0:04:28s\n",
      "epoch 32 | loss: 0.32946 | val_0_accuracy: 0.94511 |  0:04:36s\n",
      "epoch 33 | loss: 0.3317  | val_0_accuracy: 0.94478 |  0:04:44s\n",
      "epoch 34 | loss: 0.31434 | val_0_accuracy: 0.93219 |  0:04:52s\n",
      "epoch 35 | loss: 0.3022  | val_0_accuracy: 0.95067 |  0:05:01s\n",
      "epoch 36 | loss: 0.29478 | val_0_accuracy: 0.95111 |  0:05:09s\n",
      "epoch 37 | loss: 0.29236 | val_0_accuracy: 0.9537  |  0:05:17s\n",
      "epoch 38 | loss: 0.28096 | val_0_accuracy: 0.95643 |  0:05:25s\n",
      "epoch 39 | loss: 0.28007 | val_0_accuracy: 0.95509 |  0:05:34s\n",
      "epoch 40 | loss: 0.27206 | val_0_accuracy: 0.9556  |  0:05:42s\n",
      "epoch 41 | loss: 0.26308 | val_0_accuracy: 0.95228 |  0:05:50s\n",
      "epoch 42 | loss: 0.26066 | val_0_accuracy: 0.97038 |  0:05:58s\n",
      "epoch 43 | loss: 0.25143 | val_0_accuracy: 0.95823 |  0:06:07s\n",
      "epoch 44 | loss: 0.24697 | val_0_accuracy: 0.95561 |  0:06:15s\n",
      "epoch 45 | loss: 0.23807 | val_0_accuracy: 0.95897 |  0:06:23s\n",
      "epoch 46 | loss: 0.23461 | val_0_accuracy: 0.97313 |  0:06:31s\n",
      "epoch 47 | loss: 0.22876 | val_0_accuracy: 0.95706 |  0:06:40s\n",
      "epoch 48 | loss: 0.22905 | val_0_accuracy: 0.96281 |  0:06:48s\n",
      "epoch 49 | loss: 0.22263 | val_0_accuracy: 0.96322 |  0:06:56s\n",
      "epoch 50 | loss: 0.22058 | val_0_accuracy: 0.96407 |  0:07:04s\n",
      "epoch 51 | loss: 0.21822 | val_0_accuracy: 0.96472 |  0:07:13s\n",
      "epoch 52 | loss: 0.20855 | val_0_accuracy: 0.96515 |  0:07:21s\n",
      "epoch 53 | loss: 0.2072  | val_0_accuracy: 0.97485 |  0:07:29s\n",
      "epoch 54 | loss: 0.19994 | val_0_accuracy: 0.97593 |  0:07:37s\n",
      "epoch 55 | loss: 0.20227 | val_0_accuracy: 0.9629  |  0:07:46s\n",
      "epoch 56 | loss: 0.19787 | val_0_accuracy: 0.96224 |  0:07:54s\n",
      "epoch 57 | loss: 0.1958  | val_0_accuracy: 0.96287 |  0:08:02s\n",
      "epoch 58 | loss: 0.19949 | val_0_accuracy: 0.96185 |  0:08:10s\n",
      "epoch 59 | loss: 0.18907 | val_0_accuracy: 0.96407 |  0:08:18s\n",
      "epoch 60 | loss: 0.18087 | val_0_accuracy: 0.94133 |  0:08:27s\n",
      "epoch 61 | loss: 0.17795 | val_0_accuracy: 0.96917 |  0:08:35s\n",
      "epoch 62 | loss: 0.1876  | val_0_accuracy: 0.93631 |  0:08:43s\n",
      "epoch 63 | loss: 0.17926 | val_0_accuracy: 0.95655 |  0:08:51s\n",
      "epoch 64 | loss: 0.17635 | val_0_accuracy: 0.95385 |  0:09:00s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_accuracy = 0.97593\n"
     ]
    }
   ],
   "source": [
    "print(f'{optimizer_fn.__name__}, {train_ratio}, {val_ratio: .2f}, {test_ratio}, long = {window_size_long} short = {window_size_short}, {overlap_ratio}, lr = {optimizer_params}, batch_size = {batch_size}, no_weigth_loss, patience = {patience}, val_acc = ?, test_acc = ?, no Norm, no Simul')\n",
    "\n",
    "weight_for_class = []\n",
    "total_obs = len(y_train)\n",
    "# check\n",
    "for key, value in sorted(Counter(y_train).items()):\n",
    "    print(f'{key} is in event, {value}')\n",
    "    weight_for_class.append(1 - (value/total_obs))\n",
    "\n",
    "max_epochs = 200\n",
    "weight_for_class = torch.Tensor(weight_for_class).type(torch.float32)\n",
    "print(\"loss function weight:\", weight_for_class)\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=optimizer_fn,\n",
    "    optimizer_params=optimizer_params,#1e-2\n",
    "    # cat_emb_dim = [window_size, window_size, window_size, window_size, window_size]\n",
    "    )  #TabNetRegressor()\n",
    "\n",
    "result = clf.fit(\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric = [\"accuracy\", ],\n",
    "    loss_fn = nn.CrossEntropyLoss(weight_for_class),\n",
    "    # loss_fn = nn.CrossEntropyLoss(),\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs,\n",
    "    drop_last = True,\n",
    "    patience = patience\n",
    ")\n",
    "# AdamW, 0.7,  0.15, 0.15, long = 1200 short = 1200, 0.95, lr = {'lr': 0.001}, batch_size = 64, no_weigth_loss, patience = 10, val_acc = 0.96924, test_acc = 0.954, no Norm, no Simul\n",
    "# AdamW, 0.7,  0.15, 0.15, long = 1200 short = 1200, 0.95, lr = {'lr': 0.001}, batch_size = 128, no_weigth_loss, patience = 15, val_acc = .883, test_acc = .957, no Norm, no Simul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9426322035370054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     21410\n",
      "           3       0.87      0.92      0.89      3799\n",
      "           4       0.92      0.94      0.93      9310\n",
      "           5       0.00      0.00      0.00        30\n",
      "           7       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94     34549\n",
      "   macro avg       0.55      0.56      0.56     34549\n",
      "weighted avg       0.95      0.94      0.94     34549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(accuracy_score(preds, y_test))\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving_path_name = './tabnet_test_acc_9904'\n",
    "# clf.save_model(saving_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (main, Mar  8 2023, 09:31:56) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a4b37ad9db526a544fbe558cbc658e019a09612a6280b3580d69773eabd1425"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
