{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "from google.colab import drive\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from datasets import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler # 표준화 패키지 라이브러리\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from warnings import filterwarnings\n",
    "import gc\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filterwarnings('ignore')\n",
    "device = torch.device('cpu')\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/*.pkl'\n",
    "\n",
    "file_lst = sorted(glob(path))[1:]\n",
    "file_lst[6] = './data/pre_processed_split_0tpt_data_6.pkl'\n",
    "pca_file_lst = sorted(glob('../kyungho/3W-main/data/total_data_psudo_labeling*.pkl'))\n",
    "print(file_lst, pca_file_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, paths in enumerate(zip(file_lst,pca_file_lst)):\n",
    "    file_path, pca_path = paths\n",
    "    print(i, file_path, pca_path)\n",
    "    with open(file_path, 'rb') as f:\n",
    "        globals()['df_event_{}'.format(i)] = pickle.load(f)\n",
    "        globals()['df_event_{}'.format(i)].reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier 제거\n",
    "- 참고: https://stackoverflow.com/questions/35827863/remove-outliers-in-pandas-dataframe-using-percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add delta and remove outlier\n",
    "def add_delta(data_frame):\n",
    "    for column in ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP']:\n",
    "        column_pctchg = column+'_pctchg'\n",
    "        data_frame[column_pctchg] = data_frame.groupby(['id_label'])[column].pct_change()\n",
    "        data_frame[column_pctchg][data_frame[column_pctchg].isna()] = 0\n",
    "    return data_frame\n",
    "\n",
    "def remove_outlier(df):\n",
    "    target_cols = ['P-PDG', 'P-TPT', 'T-TPT','P-MON-CKP', 'T-JUS-CKP',]\n",
    "    df = df[df['id_label'].str.startswith('WELL')]\n",
    "    df = add_delta(df)\n",
    "    Q1 = df[target_cols].quantile(0.25)\n",
    "    Q3 = df[target_cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[~((df[target_cols] < (Q1 - 1.5 * IQR)) | (df[target_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return df\n",
    "\n",
    "df_event_0_out = remove_outlier(df_event_0)\n",
    "df_event_1_out = remove_outlier(df_event_1)\n",
    "df_event_2_out = remove_outlier(df_event_2)\n",
    "df_event_3_out = remove_outlier(df_event_3)\n",
    "df_event_4_out = remove_outlier(df_event_4)\n",
    "df_event_5_out = remove_outlier(df_event_5)\n",
    "df_event_6_out = remove_outlier(df_event_6)\n",
    "df_event_7_out = remove_outlier(df_event_7)\n",
    "df_event_8_out = remove_outlier(df_event_8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the list of each data type(WELL, SIMULATED, DRAWN)\n",
    "instance_dict = {'WELL': [], 'SIMULATED': [], 'DRAWN': []}\n",
    "for i in range(9):\n",
    "  instance_lst = list(globals()['df_event_{}'.format(i)]['id_label'].unique())\n",
    "  for instance in instance_lst:\n",
    "    if instance.startswith('WELL'):\n",
    "      instance_dict['WELL'].extend([instance])\n",
    "    elif instance.startswith('SIMULATED'):\n",
    "      instance_dict['SIMULATED'].extend([instance])\n",
    "    elif instance.startswith('DRAWN'):\n",
    "      instance_dict['DRAWN'].extend([instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of events in 'WELL' data\n",
    "class_lst = []\n",
    "for i in instance_dict['WELL']:\n",
    "  class_lst.append(i.split('_')[-1])\n",
    "Counter(class_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test instances\n",
    "def split_train_test_instance(instance_dict, dTypes = ['WELL', 'SIMULATED', 'DRAWN'],train_ratio = 0.6, test_ratio = 0.2):\n",
    "    total_len = 0\n",
    "    simul_drawn_lst = []\n",
    "    for dType in dTypes:\n",
    "        total_len += len(instance_dict[dType])\n",
    "        simul_drawn_lst += instance_dict[dType]\n",
    "    well_len = len(instance_dict['WELL'])\n",
    "\n",
    "    num_of_test = int(total_len*test_ratio)\n",
    "    num_of_val = int(total_len*(1-train_ratio-test_ratio))\n",
    "    num_of_train = total_len - num_of_test - num_of_val\n",
    "\n",
    "    # extract test_lst first(Only WELL data)\n",
    "    test_lst = random.sample(instance_dict['WELL'], num_of_test)\n",
    "    \n",
    "    # then make whole lst --> shuffle lst --> split train validation set\n",
    "    rest_well_lst = [i for i in instance_dict['WELL'] if i not in test_lst]\n",
    "    total_lst = rest_well_lst + simul_drawn_lst\n",
    "    random.shuffle(total_lst)\n",
    "\n",
    "    train_lst = total_lst[:num_of_train]\n",
    "    val_lst = total_lst[num_of_train:]\n",
    "\n",
    "    return train_lst, val_lst, test_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "test_ratio = 0.15\n",
    "val_ratio = 1 - train_ratio - test_ratio\n",
    "dTypes = ['WELL', 'SIMULATED', 'DRAWN']\n",
    "train_lst, val_lst, test_lst = split_train_test_instance(instance_dict, dTypes = dTypes, train_ratio = train_ratio, test_ratio = test_ratio)\n",
    "\n",
    "print(train_lst, len(train_lst), val_lst, len(val_lst), test_lst, len(test_lst), sep = '\\n')\n",
    "print('total number of lst:', len(instance_dict['WELL'])+len(instance_dict['DRAWN'])+len(instance_dict['SIMULATED']))\n",
    "print('total number of lst after removing duplicated:', len(set(train_lst + val_lst + test_lst)))\n",
    "print('train:', sorted(set([i.split('_')[-1] for i in train_lst])), 'val:', sorted(set([i.split('_')[-1] for i in val_lst])), 'test:', sorted(set([i.split('_')[-1] for i in test_lst])), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고: https://rfriend.tistory.com/590\n",
    "def make_empty_df(pca_n_components):\n",
    "    pca_lst = ['pca_1', 'pca_2','pca_3', 'pca_4', 'pca_5']\n",
    "    columns = ['P-PDG', 'P-PDG_std','P-PDG_pctchg_mean', 'P-PDG_pctchg_std',\n",
    "               'P-TPT', 'P-TPT_std', 'P-TPT_pctchg_mean', 'P-TPT_pctchg_std',\n",
    "               'T-TPT', 'T-TPT_std', 'T-TPT_pctchg_mean', 'T-TPT_pctchg_std',\n",
    "               'P-MON-CKP', 'P-MON-CKP_std', 'P-MON-CKP_pctchg_mean', 'P-MON-CKP_pctchg_std',\n",
    "               'T-JUS-CKP', 'T-JUS-CKP_std', 'T-JUS-CKP_pctchg_mean', 'T-JUS-CKP_pctchg_std',\n",
    "               'class',]\n",
    "    columns.extend(pca_lst[:pca_n_components])\n",
    "    data_frame = pd.DataFrame(columns=columns)\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def apply_window(data_frame, window_size = 5000, overlap_ratio = 0.2, pca_n_components = 2):\n",
    "    if pca_n_components:\n",
    "        pca = PCA(n_components=pca_n_components)\n",
    "    \n",
    "    new_df = make_empty_df(pca_n_components)\n",
    "    for n in tqdm(range(int(len(data_frame)/(window_size*(1-overlap_ratio))))):\n",
    "        try:\n",
    "            if int(window_size*(n+1) - window_size*overlap_ratio*n) <= len(data_frame):\n",
    "                # print(window_size*n*(1-overlap_ratio),window_size*(n+1) - window_size*overlap_ratio*n)\n",
    "                sliced_df = data_frame[int(window_size*n*(1-overlap_ratio)):int(window_size*(n+1) - window_size*overlap_ratio*n)]\n",
    "                pca_data = pca.fit_transform(sliced_df.drop( ['id_label','class'], axis=1))\n",
    "                if any(sliced_df['class'] != 0):\n",
    "                    class_label =  int(sliced_df['class'].value_counts().index[sliced_df['class'].value_counts().index < 10][0]) # 기본 모드\n",
    "                    \n",
    "                    # class_label = 1\n",
    "                else:\n",
    "                    # continue\n",
    "                    class_label = 0\n",
    "                new_df = pd.concat([new_df,pd.DataFrame({'P-PDG':[sliced_df['P-PDG'].mean()],\n",
    "                                                        'P-PDG_std':[sliced_df['P-PDG'].std()],\n",
    "                                                        'P-PDG_pctchg_mean':[sliced_df['P-PDG_pctchg'].mean()],\n",
    "                                                        'P-PDG_pctchg_std':[sliced_df['P-PDG_pctchg'].std()],\n",
    "                                                        'P-TPT':[sliced_df['P-TPT'].mean()],\n",
    "                                                        'P-TPT_std':[sliced_df['P-TPT'].std()],\n",
    "                                                        'P-TPT_pctchg_mean':[sliced_df['P-TPT_pctchg'].mean()],\n",
    "                                                        'P-TPT_pctchg_std':[sliced_df['P-TPT_pctchg'].std()],\n",
    "                                                        'T-TPT':[sliced_df['T-TPT'].mean()],\n",
    "                                                        'T-TPT_std':[sliced_df['T-TPT'].std()],\n",
    "                                                        'T-TPT_pctchg_mean':[sliced_df['T-TPT_pctchg'].mean()],\n",
    "                                                        'T-TPT_pctchg_std':[sliced_df['T-TPT_pctchg'].std()],\n",
    "                                                        'P-MON-CKP':[sliced_df['P-MON-CKP'].mean()],\n",
    "                                                        'P-MON-CKP_std':[sliced_df['P-MON-CKP'].std()],\n",
    "                                                        'P-MON-CKP_pctchg_mean':[sliced_df['P-MON-CKP_pctchg'].mean()],\n",
    "                                                        'P-MON-CKP_pctchg_std':[sliced_df['P-MON-CKP_pctchg'].std()],\n",
    "                                                        'T-JUS-CKP':[sliced_df['T-JUS-CKP'].mean()],\n",
    "                                                        'T-JUS-CKP_std':[sliced_df['T-JUS-CKP'].std()],\n",
    "                                                        'T-JUS-CKP_pctchg_mean':[sliced_df['T-JUS-CKP_pctchg'].mean()],\n",
    "                                                        'T-JUS-CKP_pctchg_std':[sliced_df['T-JUS-CKP_pctchg'].std()],\n",
    "                                                        'class': class_label,\n",
    "                                                        'pca_1':[pca_data[:,0].mean()],\n",
    "                                                        'pca_2':[pca_data[:,1].mean()],\n",
    "                                                        #'pca_3':[pca_data.iloc[:,2].mean()],\n",
    "                                                        })])\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    return new_df\n",
    "\n",
    "def build_dataset(data_frame, train_lst, val_lst, test_lst, window_size = 5000, overlap_ratio = 0.2, pca_n_components = 2):\n",
    "  gc.collect()\n",
    "  train_data_frame = data_frame[data_frame['id_label'].isin(train_lst)]\n",
    "  val_data_frame = data_frame[data_frame['id_label'].isin(val_lst)]\n",
    "  test_data_frame = data_frame[data_frame['id_label'].isin(test_lst)]\n",
    "\n",
    "#   train_data_frame = remove_outlier(train_data_frame)\n",
    "\n",
    "  train_df = apply_window(train_data_frame, window_size = window_size, overlap_ratio = overlap_ratio)\n",
    "  val_df = apply_window(val_data_frame, window_size = window_size, overlap_ratio = overlap_ratio)\n",
    "  test_df = apply_window(test_data_frame, window_size = window_size, overlap_ratio = overlap_ratio)\n",
    "  return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying window\n",
    "window_size = 1200\n",
    "window_size_short = window_size\n",
    "window_size_long =  window_size\n",
    "pca_n_components = 2\n",
    "overlap_ratio = 0.95\n",
    "\n",
    "df_event_0_window_train, df_event_0_window_val, df_event_0_window_test = build_dataset(df_event_0_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_1_window_train, df_event_1_window_val, df_event_1_window_test = build_dataset(df_event_1_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_2_window_train, df_event_2_window_val, df_event_2_window_test = build_dataset(df_event_2_out, train_lst, val_lst, test_lst, window_size = window_size_short, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_3_window_train, df_event_3_window_val, df_event_3_window_test = build_dataset(df_event_3_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_4_window_train, df_event_4_window_val, df_event_4_window_test = build_dataset(df_event_4_out, train_lst, val_lst, test_lst, window_size = window_size_short, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_5_window_train, df_event_5_window_val, df_event_5_window_test = build_dataset(df_event_5_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_6_window_train, df_event_6_window_val, df_event_6_window_test = build_dataset(df_event_6_out, train_lst, val_lst, test_lst, window_size = window_size_short, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_7_window_train, df_event_7_window_val, df_event_7_window_test = build_dataset(df_event_7_out, train_lst, val_lst, test_lst, window_size = window_size_long, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "df_event_8_window_train, df_event_8_window_val, df_event_8_window_test = build_dataset(df_event_8_out, train_lst, val_lst, test_lst, window_size = window_size_short, overlap_ratio = overlap_ratio, pca_n_components = pca_n_components)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_train =  pd.concat([df_event_0_window_train.sample(int(len(df_event_0_window_train)*0.25)),\n",
    "                        df_event_1_window_train,\n",
    "                        df_event_2_window_train,\n",
    "                        df_event_3_window_train.sample(int(len(df_event_3_window_train)*0.25)),\n",
    "                        df_event_4_window_train.sample(int(len(df_event_4_window_train)*0.25)),\n",
    "                        df_event_5_window_train,\n",
    "                        df_event_6_window_train,\n",
    "                        df_event_7_window_train,\n",
    "                        df_event_8_window_train])\n",
    "\n",
    "merged_df_val =  pd.concat([df_event_0_window_val,\n",
    "                        df_event_1_window_val,\n",
    "                        df_event_2_window_val,\n",
    "                        df_event_3_window_val,\n",
    "                        df_event_4_window_val,\n",
    "                        df_event_5_window_val,\n",
    "                        df_event_6_window_val,\n",
    "                        df_event_7_window_val,\n",
    "                        df_event_8_window_val])\n",
    "\n",
    "merged_df_test =  pd.concat([df_event_0_window_test,\n",
    "                        df_event_1_window_test,\n",
    "                        df_event_2_window_test,\n",
    "                        df_event_3_window_test,\n",
    "                        df_event_4_window_test,\n",
    "                        df_event_5_window_test,\n",
    "                        df_event_6_window_test,\n",
    "                        df_event_7_window_test,\n",
    "                        df_event_8_window_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_train['class'].value_counts())\n",
    "print(merged_df_val['class'].value_counts())\n",
    "print(merged_df_test['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-PDG_pctchg_mean = -inf, 혹은 inf인 row 제외: train(14개), val(10개), test(13)\n",
    "merged_df_train = merged_df_train[~merged_df_train['P-PDG_pctchg_std'].isna()]\n",
    "merged_df_val = merged_df_val[~merged_df_val['P-PDG_pctchg_std'].isna()]\n",
    "merged_df_test = merged_df_test[~merged_df_test['P-PDG_pctchg_std'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['P-PDG', 'P-PDG_std','P-PDG_pctchg_mean', 'P-PDG_pctchg_std',\n",
    "            'P-TPT', 'P-TPT_std', 'P-TPT_pctchg_mean', 'P-TPT_pctchg_std',\n",
    "            'T-TPT', 'T-TPT_std', 'T-TPT_pctchg_mean', 'T-TPT_pctchg_std',\n",
    "            'P-MON-CKP', 'P-MON-CKP_std', 'P-MON-CKP_pctchg_mean', 'P-MON-CKP_pctchg_std',\n",
    "            'T-JUS-CKP', 'T-JUS-CKP_std', 'T-JUS-CKP_pctchg_mean', 'T-JUS-CKP_pctchg_std',\n",
    "            'pca_1', 'pca_2']\n",
    "X_train_pre, y_train = merged_df_train.loc[:,features], merged_df_train['class']\n",
    "X_train_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "# Pandas automatically applies colomn-wise function in the code above.\n",
    "# merged_new_df = (merged_df - merged_df.mean())/merged_df.std()\n",
    "features = ['P-PDG', 'P-PDG_std','P-PDG_pctchg_mean', 'P-PDG_pctchg_std',\n",
    "            'P-TPT', 'P-TPT_std', 'P-TPT_pctchg_mean', 'P-TPT_pctchg_std',\n",
    "            'T-TPT', 'T-TPT_std', 'T-TPT_pctchg_mean', 'T-TPT_pctchg_std',\n",
    "            'P-MON-CKP', 'P-MON-CKP_std', 'P-MON-CKP_pctchg_mean', 'P-MON-CKP_pctchg_std',\n",
    "            'T-JUS-CKP', 'T-JUS-CKP_std', 'T-JUS-CKP_pctchg_mean', 'T-JUS-CKP_pctchg_std',\n",
    "            'pca_1', 'pca_2']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_pre, y_train = merged_df_train.loc[:,features], merged_df_train['class']\n",
    "X_val_pre, y_val = merged_df_val.loc[:,features], merged_df_val['class']\n",
    "X_test_pre, y_test = merged_df_test.loc[:,features], merged_df_test['class']\n",
    "\n",
    "# # it seems better\n",
    "# X_train = (X_train_pre - X_train_pre.mean())/X_train_pre.std()\n",
    "# X_val = (X_val_pre - X_val_pre.mean())/X_val_pre.std()\n",
    "# X_test = (X_test_pre - X_test_pre.mean())/X_test_pre.std()\n",
    "\n",
    "# X_train = (X_train_pre)/X_train_pre.std()\n",
    "# X_val = (X_val_pre)/X_val_pre.std()\n",
    "# X_test = (X_test_pre)/X_test_pre.std()\n",
    "\n",
    "# 각 칼럼의 std는 정규화에서 제외\n",
    "columns = ['P-PDG', 'P-PDG_pctchg_mean','P-TPT','P-TPT_pctchg_mean', 'T-TPT','T-TPT_pctchg_mean', 'P-MON-CKP','P-MON-CKP_pctchg_mean', 'T-JUS-CKP','T-JUS-CKP_pctchg_mean',\n",
    "           'P-PDG_std', 'P-TPT_std', 'T-TPT_std', 'P-MON-CKP_std', 'T-JUS-CKP_std',\n",
    "           'pca_1', 'pca_2']\n",
    "\n",
    "X_train_pre.loc[:,columns] = (X_train_pre.loc[:,columns] - X_train_pre.loc[:,columns].mean())/X_train_pre.loc[:,columns].std()\n",
    "X_val_pre.loc[:,columns] = (X_val_pre.loc[:,columns] - X_val_pre.loc[:,columns].mean())/X_val_pre.loc[:,columns].std()\n",
    "X_test_pre.loc[:,columns] = (X_test_pre.loc[:,columns] - X_test_pre.loc[:,columns].mean())/X_test_pre.loc[:,columns].std()\n",
    "\n",
    "X_train = X_train_pre\n",
    "X_val = X_val_pre\n",
    "X_test = X_test_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# print(merged_df.columns)\n",
    "# features = ['P-PDG', 'P-TPT','T-TPT', 'P-MON-CKP', 'T-JUS-CKP',]\n",
    "# target = ['class']\n",
    "\n",
    "# ratio_1, ratio_2 = int(0.7*len(merged_df)), int(0.15*len(merged_df))\n",
    "\n",
    "X_train = X_train[features].values\n",
    "y_train = y_train.values.astype(int)\n",
    "\n",
    "X_val = X_val[features].values\n",
    "y_val = y_val.values.astype(int)\n",
    "\n",
    "X_test = X_test[features].values\n",
    "y_test = y_test.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "optimizer_fn = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=0.0001)\n",
    "batch_size = 64\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{optimizer_fn.__name__}, {train_ratio}, {val_ratio: .2f}, {test_ratio}, long = {window_size_long} short = {window_size_short}, {overlap_ratio}, lr = {optimizer_params}, batch_size = {batch_size}, no_weigth_loss, patience = {patience}, val_acc = ?, test_acc = ?, no Norm, no Simul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 200\n",
    "\n",
    "# weighted cross entropy\n",
    "weight_for_class = []\n",
    "total_obs = len(y_train)\n",
    "for key, value in sorted(Counter(y_train).items()):\n",
    "    print(f'{key} is in event, {value}')\n",
    "    weight_for_class.append(1 - (value/total_obs))\n",
    "\n",
    "weight_for_class = torch.Tensor(weight_for_class).type(torch.float32)\n",
    "print(weight_for_class)\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=optimizer_fn,\n",
    "    optimizer_params=optimizer_params,#1e-2\n",
    "    # cat_emb_dim = [window_size, window_size, window_size, window_size, window_size]\n",
    "    )  #TabNetRegressor()\n",
    "\n",
    "result = clf.fit(\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric = [\"accuracy\", ],\n",
    "    loss_fn = nn.CrossEntropyLoss(weight_for_class),\n",
    "    # loss_fn = nn.CrossEntropyLoss(),\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs,\n",
    "    drop_last = True,\n",
    "    patience = patience\n",
    ")\n",
    "# AdamW, 0.7,  0.15, 0.15, long = 1200 short = 1200, 0.95, lr = {'lr': 0.001}, batch_size = 64, no_weigth_loss, patience = 10, val_acc = 0.96924, test_acc = 0.954, no Norm, no Simul\n",
    "# AdamW, 0.7,  0.15, 0.15, long = 1200 short = 1200, 0.95, lr = {'lr': 0.001}, batch_size = 128, no_weigth_loss, patience = 15, val_acc = .883, test_acc = .957, no Norm, no Simul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving_path_name = './tabnet_test_acc_9904'\n",
    "# clf.save_model(saving_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
